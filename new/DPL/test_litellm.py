#!/usr/bin/env python3
"""
–ü—Ä–æ—Å—Ç–æ–π —Ç–µ—Å—Ç –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ LiteLLM —á–µ—Ä–µ–∑ proxy.merkulov.ai
"""
import os
import sys
from pathlib import Path

# –î–æ–±–∞–≤–ª—è–µ–º src –≤ –ø—É—Ç—å
sys.path.insert(0, str(Path(__file__).parent / "src"))

from dotenv import load_dotenv
from litellm import completion

# –ó–∞–≥—Ä—É–∂–∞–µ–º .env
load_dotenv()

def test_litellm():
    """–¢–µ—Å—Ç–∏—Ä—É–µ—Ç –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ LiteLLM."""
    print("üß™ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ LiteLLM –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è...")
    print(f"Model: {os.getenv('LLM_MODEL', 'gpt-4')}")
    print(f"API Base: {os.getenv('LLM_API_BASE', 'Not set')}")
    print(f"API Key: {os.getenv('LLM_API_KEY', 'Not set')[:10]}...")
    print()
    
    try:
        response = completion(
            model=os.getenv("LLM_MODEL", "gpt-4"),
            messages=[{"role": "user", "content": "Say 'Hello from LiteLLM!' in one sentence."}],
            api_key=os.getenv("LLM_API_KEY"),
            api_base=os.getenv("LLM_API_BASE"),
            timeout=30.0,
        )
        
        content = response.choices[0].message.content
        print("‚úÖ –£—Å–ø–µ—à–Ω–æ!")
        print(f"–û—Ç–≤–µ—Ç: {content}")
        return True
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞: {e}")
        print("\n–ü—Ä–æ–≤–µ—Ä—å—Ç–µ:")
        print("1. .env —Ñ–∞–π–ª —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –∏ —Å–æ–¥–µ—Ä–∂–∏—Ç –ø—Ä–∞–≤–∏–ª—å–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è")
        print("2. –ò–Ω—Ç–µ—Ä–Ω–µ—Ç —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ —Ä–∞–±–æ—Ç–∞–µ—Ç")
        print("3. API –∫–ª—é—á –¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª–µ–Ω")
        return False

if __name__ == "__main__":
    success = test_litellm()
    sys.exit(0 if success else 1)
